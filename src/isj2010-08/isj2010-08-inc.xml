<?xml version='1.0' encoding='UTF-8'?>
<!-- 
   - Standard template for ISJ magazines
  --><docbook:book xmlns:docbook='http://docbook.org/ns/docbook' xmlns:xlink='http://www.w3.org/1999/xlink' xmlns:xml='http://www.w3.org/XML/1998/namespace' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns:xi='http://www.w3.org/2001/XInclude' xsi:schemaLocation='http://docbook.org/ns/docbook docbook.xsd '>

	<docbook:info>
		<docbook:title>IDUG Solutions Journal</docbook:title>
		<docbook:copyright>
			<docbook:year>2010</docbook:year>
			<docbook:holder>International DB2 Users Group</docbook:holder>
		</docbook:copyright>
	</docbook:info>

	<!-- Here we put the first article : always the Editor's Letter -->

	<docbook:article xsi:schemaLocation='http://docbook.org/ns/docbook docbook.xsd' xml:base='file:/home/philip/workspace-3.6/ISJ/src/isj2010-08/articles/isj2010-08-editors-letter.xml'>
	<docbook:info>
		<docbook:title>From The Editor's Desk</docbook:title>
		<docbook:author>
			<docbook:personname>Philip Nelson</docbook:personname>
		</docbook:author>
	</docbook:info>
	<docbook:para>
		Welcome to the new look IDUG Solutions Journal, developed in response to your feedback received
		over the last few months.      
	</docbook:para>
	<docbook:para>
		Our main feature article this month is a case study in producing and consuming documents in ODF 
		(Open Document Format) using DB2 pureXML.   
	</docbook:para>
	<docbook:para>
		We are also pleased to have a full complement of columns from our regular contributors.
	</docbook:para>
</docbook:article>

	<!-- Feature article goes here -->

	<docbook:article xsi:schemaLocation='http://docbook.org/ns/docbook docbook.xsd' xml:base='file:/home/philip/workspace-3.6/ISJ/src/isj2010-08/articles/isj2010-08-purexml-OOo.xml'>
	<docbook:title>Using DB2 pureXML and ODF Spreadsheets</docbook:title>
	<docbook:section>
		<docbook:title>Abstract</docbook:title>
		<docbook:para>
			ODF (Open Document Format) is a file format for office documents.  At a high level, 
			the ODF specification requires five mandatory XML documents and other optional items.  
			This article will describe how DB2 pureXML could be used to handle ODF spreadsheet
			documents. Other ODF documents such as word documents, presentations, formulas, etc. 
			could also be handled by DB2 because the ODF specification refers mainly to an archive of 
			XML documents. However, for the sake of this article, we are considering only spreadsheets
			because it is easier to co-relate the rows and columns of the spreadsheet document and that 
			of a DB2 table. This article can even be further extended into an on-line document editing 
			software with .ods as file format and DB2 pureXML as the database.
		</docbook:para>
	</docbook:section>
	<docbook:section>
		<docbook:title>Introduction</docbook:title>
		<docbook:para>The ODF specification and DB2 pureXML are introduced below.</docbook:para>
		<docbook:section>
			<docbook:title>The ODF specification</docbook:title>
			<docbook:para>
				The Open Document Format specification was originally developed by
				<docbook:link xlink:href='http://www.sun.com/'>Sun</docbook:link>
				and the standard was developed by OASIS Open Document Format for
				Office Applications (Open Document) TC – OASIS ODF TC. This standard
				is based on XML format originally created and implemented by the
				OpenOffice.org office suite. In addition to being a free and open
				OASIS standard, it is published (in one of its version 1.0
				manifestations) as an ISO/IEC international standard,
				<docbook:link xlink:href='http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=43485'>
					ISO/IEC 26300:2006 Open Document Format for Office Applications (OpenDocument) v1.0</docbook:link>.
			</docbook:para>
		</docbook:section>
		<docbook:section>
			<docbook:title>DB2 pureXML</docbook:title>
			<docbook:para>
				<docbook:link xlink:href='http://www-01.ibm.com/software/data/db2/xml/'>DB2 pureXML</docbook:link>
				is IBM software for management of XML data. It eliminates much of the work typically involved in the management of XML 
				data. From validation of XML documents, to generation of documents and support for querying XML data in the form of
				<docbook:link xlink:href='http://www.w3.org/TR/xquery/'>XQuery</docbook:link> and traditional SQL, DB2 pureXML is a 
				complete solution to manage XML data in enterprise-scale databases.
			</docbook:para>
		</docbook:section>
	</docbook:section>
	<docbook:section>
		<docbook:title>The ODF document</docbook:title>
		<docbook:para>An ODF document is a zipped file of five mandatory XML
			files and other optional components. This can be seen by running your
			favorite un-zip utility to list the components. Here is the result
			after  running the unzip command on an .ods file from command line to
			list the files. The XML files are highlighted below.</docbook:para>
		<docbook:para>
			<docbook:inlinemediaobject>
				<docbook:imageobject>
					<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics1.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
				</docbook:imageobject>
			</docbook:inlinemediaobject>
		</docbook:para>
		<docbook:para>Here is a short description of XML files as seen above.
		</docbook:para>
		<docbook:table frame='all'>
			<docbook:title>XML files of an ODF document</docbook:title>
			<docbook:tgroup cols='3'>
				<docbook:thead>
					<docbook:row>
						<docbook:entry>File name</docbook:entry>
						<docbook:entry>Usage</docbook:entry>
						<docbook:entry>Location in zipped file</docbook:entry>
					</docbook:row>
				</docbook:thead>
				<docbook:tbody>	
					<docbook:row>
						<docbook:entry>manifest.xml</docbook:entry>
						<docbook:entry>Information about the files contained in	the	package</docbook:entry>
						<docbook:entry>/META-INF</docbook:entry>
					</docbook:row>
					<docbook:row>
						<docbook:entry>styles.xml</docbook:entry>
						<docbook:entry>Styles used in the document content and automatic styles used in the styles themselves</docbook:entry>
						<docbook:entry>/ (root)</docbook:entry>
					</docbook:row>
					<docbook:row>
						<docbook:entry>settings.xml</docbook:entry>
						<docbook:entry>Application-specific settings, such as the window size or printer information</docbook:entry>
						<docbook:entry>/ (root)</docbook:entry>
					</docbook:row>
					<docbook:row>
						<docbook:entry>content.xml</docbook:entry>
						<docbook:entry>Document content and automatic styles used in the content</docbook:entry>
						<docbook:entry>/ (root)</docbook:entry>
					</docbook:row>
					<docbook:row>
						<docbook:entry>meta.xml</docbook:entry>
						<docbook:entry>Document meta information, such as the author or the time of the last save action</docbook:entry>
						<docbook:entry>/ (root)</docbook:entry>
					</docbook:row>
				</docbook:tbody>
			</docbook:tgroup>
		</docbook:table>
		<docbook:para>
			For this article, we are interested in the content.xml file which will hold the contents of the document. The document 
			used for this article is a simple shopping list named Shop.ods.  Below is the spreadsheet as it appears in OpenOffice,
			with the first row highlighted. 
		</docbook:para>
		<docbook:mediaobject>
			<docbook:imageobject>
				<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics2.png' width='5.372cm' depth='5.478cm'></docbook:imagedata>
			</docbook:imageobject>
			<docbook:caption>Example ODF spreadsheet (row highlighted)</docbook:caption>
		</docbook:mediaobject>
		<docbook:para>
			And below we have part of the equivalent content.xml file, with the XML markup for the row highlighted.
		</docbook:para>
		<docbook:mediaobject>
			<docbook:imageobject>
				<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics3.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
			</docbook:imageobject>
			<docbook:caption>XML representation of ODF spreadsheet (row highlighted)</docbook:caption>
		</docbook:mediaobject>
	</docbook:section>
	<docbook:section>
		<docbook:title>A bit of hacking</docbook:title>
		<docbook:para>
			Now that we know a bit about an ODF document, let us try to create one without actually 
			running a standard software	dealing with ODF documents. As noted above, the content.xml 
			file holds the data entered while creating the spreadsheet. So, if this file is changed 
			and zipped along with the rest of the files in the original archive (that is, the .ods 
			file), we will be having a “legal” ODF spreadsheet. To test this, follow the steps below.
		</docbook:para>
		<docbook:orderedlist>
			<docbook:listitem>Open the content.xml file in a regular text editor</docbook:listitem>
			<docbook:listitem>
				In ???some figure???, the element &lt;table:table-row&gt; has been highlighted. Type in the contents of the highlighted section
					immediately as a sibling of another &lt;table:table-row&gt; element.</docbook:listitem>
			<docbook:listitem>
				In the pasted element, make a change in any of the table:table-cell/text:p element say, something like this -

				<docbook:mediaobject>
					<docbook:imageobject>
						<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics4.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
					</docbook:imageobject>
					<docbook:caption>Edited content.xml showing added row </docbook:caption>
				</docbook:mediaobject>
			</docbook:listitem>
			<docbook:listitem>
				Save the edited content.xml file in the same folder	where the Shop.ods file was unzipped into, replacing the
				older one.
			</docbook:listitem>
			<docbook:listitem>
				Select all the contents (that is, the ones mentioned in the manifest.xml file) of the unzipped folder and zip
				them. Name the zipped file as NewShop.ods.
			</docbook:listitem>
			<docbook:listitem>
				Now, open NewShop.ods in OpenOffice or IBM Lotus Symphony and confirm that the hacking is successful. Note that
				OpenOffice successfully opens a file with a .zip extension, so long it is a valid ODF document whereas Symphony 
				requires the extension to be .ods.
			</docbook:listitem>
		</docbook:orderedlist>

		<docbook:mediaobject>
			<docbook:imageobject>
				<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics5.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
			</docbook:imageobject>
			<docbook:caption>??? insert suitable caption here ???</docbook:caption>
		</docbook:mediaobject>

		<docbook:para>
			It is now clear that, to “read” an existing ODF spreadsheet in its simplest form, we have to navigate the path of the
			content.xml XML document. Similarly, to “modify” an existing ODF spreadsheet, we should generate the content.xml XML 
			document correctly. One can, of course, extend this to create and/or modify other XML documents in the .ods archive. 
			But, for the sake of this article, we will concentrate only on the creation of content.xml XML document.
		</docbook:para>
	</docbook:section>
	<docbook:section>
		<docbook:title>Scheme of this article</docbook:title>
		<docbook:para>
			With this knowledge of XML documents in an ODF document archive, we will now proceed to demonstrate the usage of DB2
			pureXML with ODF documents. We consider the scheme below.
		</docbook:para>
		<docbook:orderedlist>
			<docbook:listitem>
				We consider an ODF spreadsheet of a simple shopping list where the item name, unit of measure (UOM) and the units
				required are provided.
			</docbook:listitem>
			<docbook:listitem>
				The content.xml document of this ODF spreadsheet is imported into a DB2 table with an XML column.</docbook:listitem>
			<docbook:listitem>
				For the sake of this article we will use the LOAD statement in DB2 to load the content.xml document and ignore any
					other methods of inserting XML documents into the DB2 table.
			</docbook:listitem>
			<docbook:listitem>
				We will refer to another traditional table which stores the price list.
			</docbook:listitem>
			<docbook:listitem>
				Using the table for price list and the table with the XML column for content.xml, we will generate another content.xml
				XML document that will hold the items with their corresponding prices.
			</docbook:listitem>
		</docbook:orderedlist>
	</docbook:section>
	<docbook:section>
		<docbook:title>Inserting XML document into DB2 table</docbook:title>
		<docbook:para>
			We will consider a  table to demonstrate DB2 pureXML capabilities. The first table will be keyed via an ID column to
			differentiate multiple documents. The second column of the table will hold the content.xml file of the ODF spreadsheet 
			document in a  XML column. The DDL for this table is reproduced here:
		</docbook:para>
		<docbook:example>
			<docbook:title>DB2 table to hold content.xml file of the ODF spreadsheet</docbook:title>
			<docbook:programlisting>
				-- DOCCONTENTXML table to hold the content.xml file of a ODF document.
				-- The table is keyed on DOCID a running sequence number.
				CREATE TABLE ODF.DOCCONTENTXML 
				(
				      DOCID      INTEGER NOT NULL,
				      DOCCONTENT XML     NOT NULL
				) ;
			</docbook:programlisting>
		</docbook:example>
		<docbook:section>
			<docbook:title>IMPORT statements</docbook:title>
			<docbook:para>
				Inserting the XML document into the table can be done using a simple INSERT SQL statement or using IMPORT
				statement. However, since we have a considerably sized XML document, we will use the IMPORT statement from 
				the command line. To use the IMPORT statement, first, save the content.xml in a folder as say, ODSFolder
				and create a flat file with a single record. Save the flat file as load.txt. This record will have two values 
				separated by a comma as shown below.
			</docbook:para>
			<docbook:example>
				<docbook:title>Contents of flat file to be used for loading DOCCONTENTXML table</docbook:title>
				<docbook:programlisting>1,&lt;XDS FIL='content.xml'/&gt;</docbook:programlisting>
			</docbook:example>
			<docbook:example>
				<docbook:title>IMPORT statement to load content.xml into DOCCONTENTXML table</docbook:title>
				<docbook:programlisting>
					IMPORT FROM load.txt OF DEL 
					XML FROM ODSFolder 
					INSERT INTO ODF.DOCCONTENTXML;
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				Alternatively, IBM Data Studio Developer can be used to load into XML column as it offers a convenient GUI.
			</docbook:para>
		</docbook:section>
	</docbook:section>
	<docbook:section>
		<docbook:title>Converting the content.xml into row-column format</docbook:title>
		<docbook:section>
			<docbook:title>Getting the cell values from the XML file</docbook:title>
			<docbook:para>
				To get to the cell values of the spreadsheet, we will start with the required XPath expression. Then, we will develop a
				working query around the XPath expression to get the results.
			</docbook:para>
		</docbook:section>
		<docbook:section>
			<docbook:title>The XPath expression</docbook:title>
			<docbook:para>
				Going back to Table 2, the left column shows the first row of the spreadsheet highlighted. The right column is a part
				of the generated content.xml file and some of the elements collapsed. The relevant part are put in red boxes. The first 
				box shows the table:table element with an attribute table:name whose value is “Sheet1”. It is the name of the sheet in 
				the complete spreadsheet. This element is repeated as many times as there are sheets in the spreadsheet with the 
				table:name attribute set to the names as set by the user. The second box is the representation of the highlighted row
				in the left column. Thus, to get to, say, column B of the first row, the path to be navigated (or, the XPath expression) 
				from the root of XML document would be as below.
			</docbook:para>
			<docbook:example>
				<docbook:title>XPath expression to get first row, second column value</docbook:title>
				<docbook:programlisting>
					/office:document-content/office:body/office:spreadsheet/table:table[1]/table:table-row[1]/table:table-cell[2]/text:p
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				In other words, we start from the <code>office:document</code> element to <code>office:body</code> and then to 
				<code>office:spreadsheet</code> to look for	the first <code>table:table</code> element. The first element represents 
				the	first sheet of the spreadsheet document. Then, to get to the second column of first row we navigate to 
				<code>table:row[1]/table:cell[2]</code> and	finally to <code>text:p</code> to get the actual text of the cell.
			</docbook:para>
			<docbook:para>
				With Firefox Mozilla browser, the above XPath expression can be easily tested using the add-on Xpather (see
				Resources below).  We follow the steps below :-
			</docbook:para>
			<docbook:orderedlist>
				<docbook:listitem>Open the content.xml in Firefox Mozilla browser</docbook:listitem>
				<docbook:listitem>Right-click on the page and select 'Show in XPather'
					<docbook:mediaobject>
						<docbook:imageobject>
						<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics6.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
						</docbook:imageobject>
					</docbook:mediaobject>
				</docbook:listitem>
				<docbook:listitem>
					The XPather dialog box opens up. Enter the XPath expression in the dialog box and click 'Eval'
				</docbook:listitem>
			</docbook:orderedlist>
			
			<docbook:mediaobject>
				<docbook:imageobject>
					<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics7.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
				</docbook:imageobject>
			</docbook:mediaobject>
		</docbook:section>

		<docbook:section>
			<docbook:title>The required query </docbook:title>
			<docbook:para>
				To wrap the XPath expression into a query, we first note the XML namespaces used. The content.xml file has the
				namespaces defined as shown below :
			</docbook:para>
			<docbook:table frame='all'>
			<docbook:title>Prefix and namespace URI used in	content.xml	document</docbook:title>
				<docbook:tgroup cols='2'>
					<docbook:thead>
						<docbook:row>
							<docbook:entry>Prefix</docbook:entry>
							<docbook:entry>Namespace</docbook:entry>
						</docbook:row>
					</docbook:thead>
					<docbook:tbody>	
						<docbook:row>
							<docbook:entry><docbook:code>office</docbook:code></docbook:entry>
							<docbook:entry>
								<docbook:code>“urn:oasis:names:tc:opendocument:xmlns:office:1.0”</docbook:code>
							</docbook:entry>
						</docbook:row>
						<docbook:row>
							<docbook:entry><docbook:code>table</docbook:code></docbook:entry>
							<docbook:entry>
								<docbook:code>“urn:oasis:names:tc:opendocument:xmlns:table:1.0”</docbook:code>
							</docbook:entry>
						</docbook:row>
						<docbook:row>
							<docbook:entry><docbook:code>text</docbook:code></docbook:entry>
							<docbook:entry>
								<docbook:code>“urn:oasis:names:tc:opendocument:xmlns:text:1.0”</docbook:code>
							</docbook:entry>
						</docbook:row>
					</docbook:tbody>
				</docbook:tgroup>
			</docbook:table>

			<docbook:para>
				The query shown below will use the XML namespaces and XPath expression that we produced in the previous sections to 
				extract the	cell values from the loaded content.xml file. The highlighted text shows the XPath expression used to 
				extract cell values.
			</docbook:para>
			<docbook:example>
				<docbook:title>Query to extract cell values from content.xml into tabular format</docbook:title>
				<docbook:programlisting>
					SELECT
					X.*
					FROM
					XMLTABLE(
					XMLNAMESPACES('urn:oasis:names:tc:opendocument:xmlns:office:1.0' AS
					"office",                      
					'urn:oasis:names:tc:opendocument:xmlns:table:1.0' AS "table",
					'urn:oasis:names:tc:opendocument:xmlns:text:1.0' AS "text"),
					'db2-fn:sqlquery("SELECT
					DOCCONTENT
					FROM
					ODF.DOCCONTENTXML
					WHERE DOCID
					= 1")
					<docbook:emphasis>
						/office:document-content/office:body/office:spreadsheet/table:table[1]/table:table-row'
					</docbook:emphasis>
					COLUMNS             
					"ITEMNAME" CHARACTER (20)  PATH
					<docbook:emphasis>'table:table-cell[1]/text:p'</docbook:emphasis>,  
					"QUANTITY" DECIMAL   (4,2) PATH
					<docbook:emphasis>'table:table-cell[2]/text:p'</docbook:emphasis>,
					"UOM"      CHARACTER (5)   PATH
					<docbook:emphasis>'table:table-cell[3]/text:p'</docbook:emphasis>  
					) AS X; 
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				To see the content.xml document in traditional rows	and columns format, we create a view using the query above.
			</docbook:para>
			<docbook:example>
				<docbook:title>View on the content.xml document</docbook:title>
				<docbook:programlisting>
					CREATE VIEW ODF.V_CONTENT AS
					(
					SELECT
					X.*
					FROM
					XMLTABLE(
					XMLNAMESPACES(
						'urn:oasis:names:tc:opendocument:xmlns:office:1.0' AS	"office",                      
						'urn:oasis:names:tc:opendocument:xmlns:table:1.0'  AS "table",
						'urn:oasis:names:tc:opendocument:xmlns:text:1.0'  AS "text"
					),
					'db2-fn:sqlquery("SELECT
					 DOCCONTENT
					 FROM
					 ODF.DOCCONTENTXML
					 WHERE
					 DOCID = 1"
					)/office:document-content/office:body/office:spreadsheet/table:table[1]/table:table-row'
					COLUMNS
					"ITEMNAME" CHARACTER (20)  PATH 'table:table-cell[1]/text:p',
					"QUANTITY" DECIMAL   (4,2) PATH	'table:table-cell[2]/text:p',
					"UOM"      CHARACTER (5)   PATH	'table:table-cell[3]/text:p'
					) AS X
					);
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				A simple SELECT query on this view shows that we have successfully 'converted' the content.xml document in the ODF 
				archive for spreadsheet into a row-column format.
			</docbook:para>
			<docbook:example>
				<docbook:title>Result of SELECT on the view V_CONTENT</docbook:title>
				<docbook:programlisting>
					SELECT * FROM ODF.V_CONTENT ;

					ITEMNAME             QUANTITY UOM  
					-------------------- -------- ----
					Potato                   2.00 kg  
					Onion                    1.00 kg  
					Cucumber                 0.50 kg  
					Capsicum                 0.50 kg  
					Carrot                   0.50 kg  
					Green chilli             0.25 kg  
					Tomato                   0.25 kg  
					Curd                     0.50 L    
					Banana                   2.00 doz  
					Milk                     2.00 L    
					Groundnut Oil            5.00 L    

					11 record(s) selected.
				</docbook:programlisting>
			</docbook:example>
		</docbook:section>
	</docbook:section>
	<docbook:section>
		<docbook:title>Shopping prices</docbook:title>
		<docbook:para>
			We will now build the content.xml for an ODF spreadsheet that will hold the shopping list – discussed above – with
			an additional column for cost of items in the shopping list. We will also provide an additional row for the grand 
			total of the items in shopping list.
		</docbook:para>
		<docbook:section>
			<docbook:title>Building the list of shopping prices</docbook:title>
			<docbook:para>
				We create a simple table that holds the unit price of shopping items with the DDL shown below.
			</docbook:para>
			<docbook:example>
				<docbook:title>DDL for table to hold the shopping prices</docbook:title>
				<docbook:programlisting>
					--Table to hold the unit price of shopping items
					CREATE TABLE ODF.SHOPPER
					(ITEMNAME  CHARACTER(50),
					UNIT_PRICE DECIMAL (4,2));
 				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				This table is inserted with values such that all the item names are available in the SHOPPER table.  To obtain the
				list of item names and the cost of items, we use the following query. Note that, this query uses the view V_CONTENT. 
				We could have used the base table directly. Usage of the view makes the query 'compact' and easier to follow.
			</docbook:para>
			<docbook:example>
				<docbook:title>Query to obtain list and cost of items with grand total</docbook:title>
				<docbook:programlisting>
					SELECT
					COALESCE(P.ITEMNAME,' TOTAL')
					ITEMNAME,
					SUM(P.QUANTITY) QTY,
					COALESCE(P.UNIT_PRICE, 0) UNIT_PRICE,
					SUM(P.COST) COST
					FROM
					(SELECT
					 A.ITEMNAME,
					 A.QUANTITY,
					 B.UNIT_PRICE,
					 A.QUANTITY*B.UNIT_PRICE COST
					 FROM
					 ODF.V_CONTENT A,
					 ODF.SHOPPER B
					 WHERE
					 UPPER(A.ITEMNAME) = B.ITEMNAME
					) P
					GROUP BY
					ROLLUP(P.ITEMNAME,P.QUANTITY,P.UNIT_PRICE)
					HAVING 
					(P.ITEMNAME IS NULL OR
					 (P.ITEMNAME      IS NOT NULL AND
					  P.QUANTITY      IS NOT NULL AND
					  P.UNIT_PRICE    IS NOT NULL AND
					  SUM(P.COST)     IS NOT NULL AND
					  SUM(P.QUANTITY) IS NOT NULL
					 )
					)
					ORDER BY COALESCE(P.ITEMNAME,' ') DESC;
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				The result of the above query is shown below.
			</docbook:para>
			<docbook:example>
				<docbook:title>Result of query for obtaining list and cost of items</docbook:title>
				<docbook:programlisting>
					ITEMNAME             QTY    UNIT_PRICE COST
					   
					-------------------- ------ ---------- --------
					Tomato                 0.25       6.00     1.50
					Potato                 2.00       5.50    11.00
					Onion                  1.00       4.00     4.00
					Milk                   2.00      40.00    80.00
					Groundnut Oil          5.00		 30.00   150.00
					Green chilli           0.25       8.00     2.00
					Curd                   0.50      20.00    10.00
					Cucumber               0.50	     10.00     5.00
					Carrot                 0.50      15.00     7.50
					Capsicum               0.50      20.00    10.00
					Banana                 2.00       6.00    12.00
					TOTAL                 14.50       0.00   293.00 
				</docbook:programlisting>
			</docbook:example>
		</docbook:section>
		<docbook:section>
			<docbook:title>View with list and cost of items</docbook:title>
			<docbook:para>
				Now that we have the result of computation of cost of items, we will take this into a view. This is purely for
				convenience. We can proceed without using this view.
			</docbook:para>
			<docbook:example>
				<docbook:title>View with list and cost of items in shopping list</docbook:title>
				<docbook:programlisting>
					CREATE VIEW ODF.V_SHOP_COST AS
					(SELECT
					 COALESCE(P.ITEMNAME,' TOTAL') ITEMNAME,
					 SUM(P.QUANTITY) QTY,
					 COALESCE(P.UNIT_PRICE, 0) UNIT_PRICE,
					 SUM(P.COST) COST
					 FROM
					 (SELECT
					  A.ITEMNAME,
					  A.QUANTITY,
					  B.UNIT_PRICE,
					  A.QUANTITY*B.UNIT_PRICE COST
					  FROM
					  ODF.V_CONTENT A,
					  ODF.SHOPPER B
					  WHERE
					  UPPER(A.ITEMNAME) = B.ITEMNAME
					 ) P
					 GROUP BY
					 ROLLUP(P.ITEMNAME,P.QUANTITY,P.UNIT_PRICE)
					 HAVING 
					 (P.ITEMNAME IS NULL OR
					  (P.ITEMNAME      IS NOT NULL AND
					   P.QUANTITY      IS NOT NULL AND
					   P.UNIT_PRICE    IS NOT NULL AND
					   SUM(P.COST)     IS NOT NULL AND
					   SUM(P.QUANTITY) IS NOT NULL
					  )
					 )
					);
				</docbook:programlisting>
			</docbook:example>
		</docbook:section>
	</docbook:section>
	<docbook:section>
		<docbook:title>XQuery Update to build content.xml document</docbook:title>
		<docbook:para>
			At this point, we have 'shredded' the shopping list (from the content.xml of ODF spreadsheet), joined with the relational
			table having the unit prices of items and generated a relational output of the cost of items in shopping list with the 
			grand total. Our aim is now to convert this relational output into the format of content.xml so that the result is a 
			complete ODF spreadsheet.
		</docbook:para>
		<docbook:para>
			One way of building the content.xml is to start from scratch and building the whole of the document. This approach
			would be quite tedious. A better way would be to generate the relevant part in the content.xml part and then insert into an
			otherwise empty content.xml document. This approach will also allow	us to make use of the XQuery Update facility in DB2 
			pureXML.
		</docbook:para>
		<docbook:section>
			<docbook:title>A quick side note on XQuery Update</docbook:title>
			<docbook:para>
				XQuery is a query and functional programming language designed to query XML documents. It became a W3C Candidate
				Recommendation on 23rd January, 2007. XQuery Update facility is an extension to XQuery that allows update (insert, 
				modify and delete) of the XML documents. It became a W3C Candidate Recommendation on 14th March, 2008.
			</docbook:para>
		</docbook:section>
		<docbook:section>
			<docbook:title>Generating the content.xml for the shopping prices</docbook:title>
			<docbook:para>
				To start with, we will create a dummy content.xml that is complete and ODF compliant in all respects except it would
				resemble an empty spreadsheet. Next, we will generate XML sequences that is correct for a row and its columns of a 
				spreadsheet. Then, we will collect all of these XML sequences and insert into the dummy content.xml document.
			</docbook:para>
			<docbook:para>
				To create the dummy document, we simply open the spreadsheet for shopping list, delete all rows and columns and save
				it with another name. Then, we unzip this document and refer the content.xml document. Here is a screenshot of how 
				this document would look.
			</docbook:para>
			<docbook:mediaobject>
				<docbook:imageobject>
					<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics8.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
				</docbook:imageobject>
				<docbook:caption>content.xml for an empty spreadsheet</docbook:caption>
			</docbook:mediaobject>
			<docbook:para>
				Insert this dummy document into the ODF.DOCCONTENTXML table with DOCID as zero using the IMPORT method described before.
				Our aim now is to update this document such that, <docbook:code>&lt;table:table-row&gt;</docbook:code> elements are 
				added as children of <docbook:code>&lt;table:table&gt;</docbook:code> and as siblings of <docbook:code>
				&lt;table:table-column&gt;</docbook:code>.
			</docbook:para>
		</docbook:section>
		<docbook:section>
			<docbook:title>Building the <docbook:code>&gt;&lt;table:table-row&gt;</docbook:code> elements</docbook:title>
			<docbook:para>
				In our example, each row of spreadsheet would have four columns. Therefore, each row element, as required in content.xml, 
				would have four children for the number of columns. A sample of <docbook:code>&lt;table:table-row&gt;</docbook:code> is 
				shown below. The XML namespace declarations have been omitted for the sake of brevity.
			</docbook:para>
			<docbook:example>
				<docbook:title>A sample <docbook:code>&lt;table:table-row&gt;</docbook:code> element</docbook:title>
				<docbook:programlisting>
					&lt;table:table-row
					table:style-name="ro1"&gt;
					&lt;table:table-cell
					office:value-type="string"&gt;&lt;text:p&gt;Tomato&lt;/text:p&gt;&lt;/table:table-cell&gt;
					&lt;table:table-cell
					office:value-type="string"&gt;&lt;text:p&gt;.25&lt;/text:p&gt;&lt;/table:table-cell&gt;
					&lt;table:table-cell
					office:value-type="string"&gt;&lt;text:p&gt;6.00&lt;/text:p&gt;&lt;/table:table-cell&gt;
					&lt;table:table-cell
					office:value-type="string"&gt;&lt;text:p&gt;1.5000&lt;/text:p&gt;&lt;/table:table-cell&gt;
					&lt;/table:table-row&gt; 
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				To build the <docbook:code>&lt;table:table-row&gt;</docbook:code> elements we need to generate 
				<docbook:code>&lt;table:table-cell&gt;</docbook:code> for each column of the row in the relational table and then 
				aggregate them to a single <docbook:code>&lt;table:table-row&gt;</docbook:code> element. We will use the XMLAGG 
				function to build the elements and store in a table the generated elements so that it is easier to use while doing 
				the update of XML document. The	table to hold the generated elements is defined as shown below.
			</docbook:para>
			<docbook:example>
				<docbook:title>Table to hold generated <docbook:code>&lt;table:table-row&gt;</docbook:code> elements</docbook:title>
				<docbook:programlisting>
					CREATE TABLE ODF.SHOP_COST_XML 
					(SHOP_COST XML);
				</docbook:programlisting>
			</docbook:example>
			<docbook:example>
				<docbook:title>
					Insert generated <docbook:code>&lt;table:table-row&gt;</docbook:code> elements with <docbook:code>&lt;dummy&gt;</docbook:code> parent
				</docbook:title>
				<docbook:programlisting>
					INSERT INTO ODF.SHOP_COST_XML 
					(SHOP_COST)
					(SELECT
					 XMLDOCUMENT(
					 	XMLELEMENT(NAME "dummy",
							XMLNAMESPACES(
								'urn:oasis:names:tc:opendocument:xmlns:office:1.0' AS "office",
								'urn:oasis:names:tc:opendocument:xmlns:table:1.0'  AS "table",
								'urn:oasis:names:tc:opendocument:xmlns:text:1.0' AS "text"
							),
							XMLAGG(
								XMLELEMENT(NAME "table:table-row",
									XMLATTRIBUTES('ro1' AS "table:style-name"),
									XMLELEMENT(NAME "table:table-cell",
										XMLATTRIBUTES('string' AS "office:value-type"),            
										XMLELEMENT(NAME "text:p", STRIP(O.ITEMNAME))
									),
									XMLELEMENT(NAME "table:table-cell",
										XMLATTRIBUTES('string' AS "office:value-type"),
										XMLELEMENT(NAME "text:p", O.QTY )
									),
									XMLELEMENT(NAME "table:table-cell",
										XMLATTRIBUTES('string' AS "office:value-type"),
										XMLELEMENT(NAME "text:p", O.UNIT_PRICE )
									),
									XMLELEMENT(NAME "table:table-cell",
										XMLATTRIBUTES('string' AS "office:value-type"),
										XMLELEMENT(NAME "text:p", O.COST)
									)
								)
								ORDER BY O.ITEMNAME DESC
							)
						)
				   )
				   FROM ODF.V_SHOP_COST O
				  );
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				Finally, we are now ready to update our dummy XML document. The query to do the update is shown below. Note that,
				this query is not inserting the resulting into any table. It is left to the reader to route the output to a table 
				column, file, message queue, etc.
			</docbook:para>
			<docbook:example>
				<docbook:title>Updated content.xml document</docbook:title>
				<docbook:programlisting>
					VALUES XMLQUERY(
					'declare namespace office="urn:oasis:names:tc:opendocument:xmlns:office:1.0";
					 declare namespace table="urn:oasis:names:tc:opendocument:xmlns:table:1.0"  ;
					 transform
					 copy $dummy := db2-fn:sqlquery("SELECT DOCCONTENT FROM ODF.DOCCONTENTXML WHERE DOCID = 0") ,
					 $rows := db2-fn:sqlquery("SELECT * FROM ODF.SHOP_COST_XML")
					 modify do
					 insert $rows/dummy/* as last 
					 into $dummy/office:document-content/office:body/office:spreadsheet/table:table
					return $dummy'
					); 
				</docbook:programlisting>
			</docbook:example>
			<docbook:para>
				To test that our update has worked successfully run, we	route the output of query above to a file called content.xml.
				Replace the content.xml file in the unzipped archive of our original shopping list spreadsheet with the one created 
				now. Zip the files back and save it with name as ShopPrices.ods and open with OpenOffice. Here is the screenshot.
			</docbook:para>

			<docbook:mediaobject>
				<docbook:imageobject>
					<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics9.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
				</docbook:imageobject>
				<docbook:caption>ShopPrices.ods</docbook:caption>
			</docbook:mediaobject>

			<docbook:para>And, we are done !</docbook:para>
		</docbook:section>
	</docbook:section>
	<docbook:section>
		<docbook:title>Next steps</docbook:title>
		<docbook:para>
			Further enhancements may involve manipulating other XML documents in a ODF compliant archive. For example, the
			meta.xml document holds information about the document itself.  This information can be accessed and set by going to 
			<docbook:code>File -&gt; Properties...</docbook:code> dialog box. For example, for the document in this	article (Shop.ods), 
			this is how the dialog box looks like.
		</docbook:para>

		<docbook:mediaobject>
			<docbook:imageobject>
				<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics10.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
			</docbook:imageobject>
			<docbook:caption>Document properties</docbook:caption>
		</docbook:mediaobject>

		<docbook:para>
			The corresponding meta.xml document (partial snapshot) is shown below.
		</docbook:para>

		<docbook:mediaobject>
			<docbook:imageobject>
				<docbook:imagedata fileref='../graphics/isj2010-08-purexml-OOo-graphics11.png' width='11.17cm' depth='7.536cm'></docbook:imagedata>
			</docbook:imageobject>
			<docbook:caption>meta.xml (partial)</docbook:caption>
		</docbook:mediaobject>

		<docbook:para>
			Thus, while generating the spreadsheet, one can	write queries to generate the meta.xml document with correct values
			for 	creator, creation time-stamp, etc.
		</docbook:para>
	</docbook:section>
	<docbook:section>
		<docbook:title>Resources</docbook:title>
		<docbook:para>Important resources :</docbook:para>
		<docbook:variablelist>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www-01.ibm.com/software/data/db2/express/download.html'>DB2 Express-C</docbook:link>
				</docbook:term>
				<docbook:listitem>		
					– Version of DB2 which is free to download, develop, deploy and distribute.
				</docbook:listitem>	
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www.ibm.com/db2/9'>DB2 v9 pureXML</docbook:link>
				</docbook:term>	
				<docbook:listitem>All information about DB2 V9 pureXML</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www.ibm.com/support/docview.wss?rs=71&amp;uid=swg27009552'>DB2 v9 Product Manuals</docbook:link>
				</docbook:term>
				<docbook:listitem>
					Especially, refer the ones for XQuery and XML.
				</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>	
				<docbook:term>
					<docbook:link xlink:href='http://www-01.ibm.com/software/data/studio/'>IBM Data Studio
					</docbook:link>
				</docbook:term>	
				<docbook:listitem>
					Govern, design, develop and deploy databases and data driven applications.
				</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www.oasis-open.org/committees/office/'>ODF Specification
					</docbook:link>
				</docbook:term>	
				<docbook:listitem>Link to the complete specification</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://books.evc-cit.info/book.php'>OpenOffice.org XML essentials</docbook:link>
				</docbook:term>	
				<docbook:listitem>
					– Nice explanation of XML data formats.
				</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www.ibm.com/developerworks/xml/library/x-think15/'>Thinking XML : The open office file format
					</docbook:link>
				</docbook:term>	
				<docbook:listitem>An earlier developerWorks article discussing the file formats of OpenOffice.</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www.ibm.com/developerworks/db2/library/techarticle/dm-0705gruber/'>Manage ODF and Microsoft Office 2007 documents with DB2
						9 pureXML</docbook:link>
				</docbook:term>		
				<docbook:listitem>
					An earlier developerWorks article on using ODF and Microsoft Office documents with DB2 9 pureXML.
				</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='https://addons.mozilla.org/addon/1192'>XPather add-on</docbook:link>
				</docbook:term>	
				<docbook:listitem>Nifty tool for Firefox Mozilla users to quickly check an XPath expression</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>
					<docbook:link xlink:href='http://www.ibm.com/developerworks/db2/library/techarticle/dm-0710nicola/%5C'>Update XML in DB2 9.5</docbook:link>
				</docbook:term>		
				<docbook:listitem>Nice article on developerWorks explaining update of XML documents</docbook:listitem>
			</docbook:varlistentry>
		</docbook:variablelist>
	</docbook:section>
	<docbook:section>
		<docbook:title>Biography</docbook:title>
		<docbook:para>Nagesh Subrahmanyam is a Software Developer in IBM
			Global Services, India......</docbook:para>
	</docbook:section>
</docbook:article>

	<!-- Column 1 -->

	<docbook:article xsi:schemaLocation='http://docbook.org/ns/docbook docbook.xsd' xml:base='file:/home/philip/workspace-3.6/ISJ/src/isj2010-08/articles/isj2010-08-rmiller.xml'>
	<docbook:info>
		<docbook:title>Giving You A Reason</docbook:title>
		<docbook:subtitle>Compelling Reasons to Upgrade DB2</docbook:subtitle>
		<docbook:author>
			<docbook:personname>Roger Miller</docbook:personname>
		</docbook:author>
	</docbook:info>
	<docbook:para>
		<docbook:mediaobject>
			<docbook:imageobject>
				<docbook:imagedata fileref='../graphics/isj2010-08-rmiller-graphics1.png'></docbook:imagedata>

			</docbook:imageobject>
		</docbook:mediaobject>
	</docbook:para>
	<docbook:para>
		Is your current bowl getting tight?  What is limiting you?  Is it CPU? Virtual storage?  Latching?  
		Catalog and directory?  Utilities?  Are you currently running DB2 9? V8? V7?  Upgrading to a bigger 
		bowl may be just what you need.
	</docbook:para>
	<docbook:section>
		<docbook:title>
			Should you upgrade to DB2 10?
		</docbook:title>
		<docbook:para>
			To 10, or not to 10, when and how are the questions. 
			Whether 'tis nobler in the mind to suffer the slings and arrows of outrageous limits, 
			Or to take arms against a sea of troubles, And by upgrading, end them?  
			To die: to sleep; No more; and by a sleep to say we end the heart-aches and the thousand 
			natural shocks that old versions are heir to. ‘tis a consummation devoutly to be wished. 
			To die, to sleep. To sleep: perchance to dream: ay, there’s the rub; 
			For in that sleep of death what dreams may come when versions have shuffled off this mortal coil, 
			must give us pause: 
			There’s the respect that makes calamity of too long life for old versions.  
			[ With abject apologies to the Bard and to Hamlet act 3 scene 1]
		</docbook:para>
	
		<docbook:para>
			The answer to upgrading to 10 is a definite Yes.  The question is not so much whether to upgrade 
			as when and how to upgrade.  If you are running DB2 9 today, then DB2 10 is in your near future, 
			giving you more room to grow, with higher limits, lower costs, and more for less.  If you are 
			running DB2 V8 today, then you have a choice of jumping to DB2 9 or directly to DB2 10.  
			So the key question is …
		</docbook:para>
	</docbook:section>
	
	<docbook:section>
		<docbook:title>
			When and how should I upgrade to DB2 10?
		</docbook:title>
		<docbook:para>		
		As of early August 2010, DB2 10 is in beta.  Some of the key information for making this 
		decision is known, but some is not yet.  DB2 for z/OS V8 end of service is set for April 2012, 
		21 months from now. The unknown information includes the date for DB2 10 general availability, 
		V8 extended service, and pricing, which will come in later announcements.
		</docbook:para>
		<docbook:para>	  
		While DB2 10 is expected to be better than prior versions, it will have maturity, stability, 
		and service delivery similar to other software and versions, with more defects at first, 
		then fewer as the software matures.  Determining when the software is ready for a specific 
		customer and when the customer is ready for the software depends upon the specific customer 
		resources, prior experience, and the value for the improvements versus the need for stability.  
		Many customers depend upon tools or other software, and having that software that works with 
		DB2 is a prerequisite.  When this information is known, we can help answer the question.  
		This web page can help.   
		<docbook:link xlink:href='http://www.ibm.com/support/docview.wss?uid=swg21006951'></docbook:link> 
		Content of the two versions is available, although the details of DB2 10 are still not public.  
		Here is a summary of the two versions -
		</docbook:para>
	</docbook:section>
	
	<docbook:section>
		<docbook:title>
		DB2 9: Robust, Scalable, Available and Easily Manageable
		</docbook:title>
		<docbook:para>
		DB2 9 delivers CPU reductions for utilities that are generally in the range of 20% to 30%.  
		Customers report saving terabytes of disk space using index compression.  More CPU time 
		is shifted to zIIP processors, reducing costs.  Security is improved with more flexible 
		trusted contexts and roles. Resilience is improved as more changes can be made while 
		applications keep running.  One table can be replaced quickly with a clone.  Indexes 
		and columns can be renamed.  Many more utilities can be online.
		</docbook:para>
		<docbook:para>
		DB2 9 delivers seamless integration of XML and relational data with pureXML and makes big 
		strides in SQL for productivity and portability of applications.  A new storage structure 
		is introduced for large tables.  Today’s complex applications include both transactions 
		and reporting, so performing both well is required. The key improvements for reporting are 
		optimization enhancements to improve query and reporting performance and ease of use. More 
		queries can be expressed in SQL with new SQL enhancements.  Improved data is provided for the 
		optimizer, with improved algorithms. Improved CPU and elapsed times can be achieved with the 
		FETCH FIRST clause specified on a subquery. The INTERSECT and EXCEPT clauses make SQL easier 
		to write.  
		</docbook:para>
	</docbook:section>
	
	<docbook:section>
		<docbook:title>
		DB2 10: Cut costs and improve performance
		</docbook:title>
		<docbook:para>
		DB2 10 for z/OS provides the best reduction in CPU for transactions and batch in over 20 years. 
		We expect most customers to reduce CPU times between 5% and 10% initially, with the opportunity 
		for much more. Applications which can take advantage of additional benefits, such as hash access, 
		can have larger CPU and memory reductions. 
		</docbook:para>
		<docbook:para>
		Scalability is the second major benefit, with the ability to run five to ten times as many 
		threads in a single subsystem by moving 80% to 90% of the virtual storage above the bar. 
		Schema evolution or data definition on demand enhancements improves availability. SQL and 
		pureXML improvements extend usability and application portability for this platform. 
		Productivity improvements for application developers and for database administrators are 
		very important as data grows in scale and complexity. 
		</docbook:para>
	</docbook:section>
	
	<docbook:section>
		<docbook:title>
			Questions for you
		</docbook:title>
		<docbook:para>
		The right answer is not “One size fits all.”  If we know the key factors for you, we can help you 
		make a better choice.  Here are some of the key objectives.  Which ones are most important for you?
		</docbook:para>	
		<docbook:itemizedlist>
			<docbook:listitem>	  
			Performance improves in both DB2 9 and 10, with larger CPU reductions in DB2 10.
			</docbook:listitem>
			<docbook:listitem>	  
			Scalability is improved a little in DB2 9 and a lot in DB2 10.
			</docbook:listitem>
			<docbook:listitem>	  
			Availability is enhanced in both, with more online changes in both.
			</docbook:listitem>
			<docbook:listitem>	  
			Security is made stronger and more flexible with roles in DB2 9 and with more options in DB2 10.
			</docbook:listitem>
			<docbook:listitem>	  
			Productivity is helped in both releases, with more improvements in DB2 10.  Upgrading to DB2 9 
			is easier than to DB2 10 from DB2 V8.  
			</docbook:listitem>
			<docbook:listitem>	  
			Stability is better in more mature versions. 
			</docbook:listitem>
			<docbook:listitem>	  
			Skills: What skill set is available within your organization?  Do you have people with the 
			right skills and time to plan and run a project?  DB2 planning workshops can help with 
			education.  Transition classes provide more education for one or both versions.  Services 
			could be used if the skills are not presently available.  
			</docbook:listitem>
			<docbook:listitem>	  
			Technology adoption model: Are you using the latest technology that is being shipped, or are the 
			operating system and hardware back-level?  Is the technology one level back, two or more? This 
			question tells both how much work will be required and the comfort level of your organization 
			for running the latest version.
			</docbook:listitem>
			<docbook:listitem>	  
			Platform management practices: What are your platform management practices? What type of change 
			management practices are in place?  How robust is your testing for new software? What is the 
			inventory of software and tools?  How many vendors are involved?  Which ones?  Almost every 
			vendor has software ready for DB2 9, but DB2 10 may take some time after general availability.
			</docbook:listitem>
			<docbook:listitem>	  
			Numbers of servers: How many LPARs and subsystems does the organization have? An organization that 
			has 100 subsystems has a different set of challenges than does one that has 5 subsystems.  
			</docbook:listitem>
			<docbook:listitem>	  
			Organizational considerations: What additional organizational factors, such as politics and 
			policies, must be considered?
			</docbook:listitem>
		</docbook:itemizedlist>
	</docbook:section>
	
	<docbook:section>
		<docbook:title>
			What version are you running?
		</docbook:title>
		<docbook:para>
		Here are the primary recommendations for customers who are running various DB2 versions.
		</docbook:para>
		<docbook:variablelist>
			<docbook:varlistentry>
				<docbook:term>DB2 9</docbook:term>
				<docbook:listitem>
					<docbook:para>	
		If you are on DB2 9 today, then you are a good candidate for an early upgrade to DB2 10, 
		especially if your custom is to move in the first year after general availability.  Listen to 
		reports from early customers and upgrade for the value.
					</docbook:para>
				</docbook:listitem>
			</docbook:varlistentry>	
			<docbook:varlistentry>
				<docbook:term>V8</docbook:term>
				<docbook:listitem>
					<docbook:para>	
		If you are on DB2 V8 today, then the next questions are on timing for you and readiness 
		for the new version.  How soon after general availability do you normally upgrade?  Are you still 
		in the process of moving to NFM or have you recently finished V8 upgrade?   If you just finished, 
		then you probably will wait a few years and use the skip.  If you have resources for an upgrade, 
		but DB2 10 is too new, then DB2 9 is probably your next move.  If you have the resources and can 
		work with a new version, then skipping to DB2 10 may work for you.
					</docbook:para>
				</docbook:listitem>
			</docbook:varlistentry>
			<docbook:varlistentry>
				<docbook:term>V7</docbook:term>
				<docbook:listitem>
					<docbook:para>	
		If you are currently on DB2 V7, then upgrade to DB2 V8.  Then you can use the skip version 
		upgrade to DB2 10 in a few years.
					</docbook:para>	
				</docbook:listitem>
			</docbook:varlistentry>
		</docbook:variablelist>
		<docbook:para>
		DB2 has several new versions and upgrade paths for you to consider.  This story will be changing, 
		but you can hear the latest at IDUG conferences and on the web.  DB2 9 is ready for you now.  
		DB2 10 is still in beta, but is delivering higher limits, lower costs, and more for less.
		</docbook:para>	  

		<docbook:itemizedlist>
			<docbook:listitem>
			<docbook:link xlink:href='http://www.ibm.com/software/data/db2/zos/db2-10/'></docbook:link>
			</docbook:listitem> 
			<docbook:listitem>
			<docbook:link xlink:href='http://www.ibm.com/data/db2/zos'></docbook:link>
			</docbook:listitem> 
		</docbook:itemizedlist>
	</docbook:section>

</docbook:article>

	<!-- Column 2 -->

	<docbook:article xsi:schemaLocation='http://docbook.org/ns/docbook docbook.xsd' xml:base='file:/home/philip/workspace-3.6/ISJ/src/isj2010-08/articles/isj2010-08-cmullins.xml'>
	<docbook:info>
		<docbook:title>DB2 and Storage Management</docbook:title>
		<docbook:author>
			<docbook:personname>Craig S. Mullins</docbook:personname>
		</docbook:author>
	</docbook:info>
	<docbook:para>
		As an IT professional who uses DB2, you know that all database management systems rely on some form persistent storage to 
		maintain data. That means that the DBMS interoperates with operating system files, or data sets. As such, some form of 
		storage management should be a key part of the database operations required of a DBA. Typically database storage means 
		disk devices or subsystems, but it can also mean solid state disk, removable storage, or even trusty “old” tape devices.
	</docbook:para>
	<docbook:section>
		<docbook:title>DB2 Storage Basics</docbook:title>
		<docbook:para>
			At the most basic level it is important to know that DB2 stores its data in VSAM Linear Data Sets (LDS). Each table space 
			and index space you create requires at least one, possibly more, underlying VSAM data sets. DB2 uses VSAM Media Manager 
			for its I/O operations. For every I/O, VSAM Media Manager builds a channel program and sends a request to the I/O supervisor.
		</docbook:para>	
		<docbook:para>
			But let’s back up a moment. The following items are the core of the storage-related objects and items you will need to know 
			about for DB2 for z/OS:-
			<docbook:variablelist>
				<docbook:varlistentry>
					<docbook:term>DB2 Storage Groups</docbook:term>
					<docbook:listitem>
						<docbook:para>
							List of disk volumes. DB2 can also work with SMS so you will need to differentiate between DB2 storage groups 
							and SMS storage groups (see Figure 1).
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Table Spaces</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk as at least one VSAM LDS data set
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Indexes</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk (in an index space) as at least one VSAM LDS data set
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>			
				<docbook:varlistentry>
					<docbook:term>System data sets</docbook:term>
					<docbook:listitem>
						<docbook:para>
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Active Log</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Archive Logs</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk or tape
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>BSDS</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Image Copy Backups</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk or tape
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Image Copy Backups</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Stored on disk or tape
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>DB2 library data sets</docbook:term>
					<docbook:listitem>
						<docbook:para>
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>Temporary data sets</docbook:term>
					<docbook:listitem>
						<docbook:para>
							Used by utilities
						</docbook:para>
					</docbook:listitem>
				</docbook:varlistentry>
			</docbook:variablelist>	
		</docbook:para>

Figure 1. DB2 Storage Groups vs. SMS Storage Groups

		<docbook:para>
			So you can see that there are multiple areas within DB2 that require storage and need to be managed. This article will touch 
			upon most of these areas. But back to data set basics for the time being. 
		</docbook:para>
		<docbook:para>
			You may have noticed that I said that multiple data sets may be required so when does DB2 utilize multiple VSAM data sets 
			for a table space or index? There are three situations where this will arise:-
			<docbook:orderedlist>
				<docbook:listitem>
					When the object is partitioned, each partition will reside in a separate data set.
				</docbook:listitem>
				<docbook:listitem>
					When a data set in a segmented or simple table space reaches its maximum size of 2 GB, DB2 can automatically create 
					a new data set. 
				</docbook:listitem>
				<docbook:listitem>
					When the table space is cloned; each clone has its own underlying data set(s).
				</docbook:listitem>
			</docbook:orderedlist>
		</docbook:para>
		<docbook:para>
			To understand how DB2 accommodates these situations we will need to take a look at how DB2 data sets are named. Figure 2 
			shows the naming convention for DB2 data sets. Although many of you reading this article may be familiar with this naming 
			convention, a quick review is still a good idea. The database name and the page set name (table space or index space name) 
			is part of the data set name. This is one of the reasons that you cannot have more than one table space or index space of 
			the same name in the same database. The “interesting” part of the naming convention (if a naming convention can be 
			interesting at all) comes at the end. We have an instance qualifier and a data set number. 
		</docbook:para>		


Figure 2. DB2 Data Set Naming Convention

		<docbook:para>
			The instance qualifier is used when running online REORG and CHECK utilities. For an online utility DB2 uses a shadow data 
			set and will switch from the current to the shadow after running the utility. So DB2 will switch the instance qualifier 
			between I and J when you run online  REORG and CHECK utilities. The numbers after the instance qualifier can change if you 
			use clones. Although this is not the place for a comprehensive discussion of cloning let’s skim the surface to understand 
			what happens to this portion of the data set name. Basically, cloning creates a table with the exact same attributes as a 
			table that already exists, except that it has no data. The close is created using the ALTER TABLE SQL statement with the 
			ADD CLONE parameter and the clone table is created in the same table space as the existing table… except in a different 
			VSAM data set. The base table starts with I0001 in the data set name; the clone will be I0002. This can change because 
			the SQL EXCHANGE statement flips the VSAM data sets. 
		</docbook:para>
		<docbook:para>
			Next we have the data set number, which appropriately enough, is used when a page set requires multiple data sets. The z 
			is usually an “A”, but it can be A, B, C, D, or E. For partitioned table spaces, the number is the partition number and 
			A-E is used for partitions in excess of 999. So partition 1 would be A001 and partition 1,000 would be B001, and so on. 
			For simple or segmented table spaces, the data set number starts at 001 and is incremented by one as the page set grows 
			past the maximum size of 2GB.
		</docbook:para>
		<docbook:para>
			These are the most basic storage “things” that you will need to know as you manage DB2 for z/OS storage.
		</docbook:para>
	</docbook:section>
	<docbook:section>
		<docbook:title>
			Important DB2 for z/OS Storage Issues
		</docbook:title>
		<docbook:para>
			Although storage management can be an afterthought for the DBA it really shouldn’t be. According to Gartner, Inc. the cost 
			of managing storage is 4 to 10 times the initial cost of storage acquisition. And the growth rate for disk storage was 37% 
			for the years 1996 through 2007. So storage issues are vitally important and unless it is managed appropriately it can be 
			very costly. And unmanaged DB2 storage can result in system outages, which is the last thing any DBA wants to have happen, 
			isn’t it?
		</docbook:para>
		<docbook:para>
			Even so, it is common for storage-related issues to be relegated to the backburner by DBAs. Let’s face it, most robust 
			mainframe organizations have an entire unit dedicated to storage management and administration. And the DBA has enough 
			to contend with without adding storage tasks to the list. But DBAs and storage administrators are concerned about 
			different things – and that is the way it should be. 
		</docbook:para>
		<docbook:para>
			Refer to Figure 3. The DBA has a database-centric focus, whereas the storage administrator will focus on storage issues 
			for the entire shop, focusing on devices and data sets. But the storage folsk are not DB2 experts, nor should they be. 
			Likewise, most DBAs are not storage experts. Making matters worse is that these two groups rarely communicate well.
		</docbook:para>

Figure 3. DBA versus Storage Administration

		<docbook:para>
			So there is a gap between Database Administration, Storage Administration and Capacity Planning. Information is available 
			to DBAs from various sources including RUNSTATS, STOSPACE, real-time statistics (RTS), DB2 Catalog, and so on, but the 
			details are scattered all over the place and it can be difficult to gain a complete, accurate, and up-to-date picture. 
			And any historical view into DB2 storage usage has to be managed manually.
		</docbook:para>
		<docbook:para>
			Think about your environment for a moment and then reflect on whether or not you can easily answer the following questions:
			<docbook:itemizedlist>
				<docbook:listitem>
					Do all of my databases have sufficient allocation to satisfy business requirements?
				</docbook:listitem>
				<docbook:listitem>
					Why is DB2 storage growing when our business is not?
				</docbook:listitem>
				<docbook:listitem>
					Am I wasting any storage?
				</docbook:listitem>
				<docbook:listitem>
					When will more storage be required?
				</docbook:listitem>
				<docbook:listitem>
					How much additional storage is needed?
				</docbook:listitem>
				<docbook:listitem>
					What needs to be done to align the additional storage with the DBMS? 
				</docbook:listitem>
			</docbook:itemizedlist>
		</docbook:para>
		<docbook:para>
			Without a tool to capture, integrate, and manage information about your DB2 storage infrastructure answering these questions 
			can be quite difficult.
		</docbook:para>
	</docbook:section>

	<docbook:section>
		<docbook:title>
			A Little Bit About Modern Disk Arrays
		</docbook:title>
		<docbook:para>
			Mainframe disk, or DASD, is usually equated to a 3380 or 3390. In other words, people think of physical hardware devices 
			with a one-to-one relationship between a disk drive and a volume. The logical view is broken down as:
			<docbook:itemizedlist>
				<docbook:listitem>
					Track size, or the number of bytes per track.
				</docbook:listitem>
				<docbook:listitem>
					Capacity, or the size of the device, in terms of number of tracks or gigabytes.
				</docbook:listitem>
				<docbook:listitem>
					Device address, which is a thread onto which I/O operations are serialized by the operating system
				</docbook:listitem>
			</docbook:itemizedlist>
		</docbook:para>
		<docbook:para>
			But the physical world is not the same as the logical anymore. Today’s modern storage architecture uses disk arrays, 
			or RAID. RAID stands for Redundant Array of Independent Disk; an array is the combination of two or more physical disk 
			storage devices in a single logical device or multiple logical devices. The array is perceived by the system to be a 
			single disk device. RAID can offer big benefits in terms of availability because the disks are typically hot-swappable, 
			meaning that a drive can be replaced while the array is up and running. There are many levels of RAID technology, each 
			delivering different levels of fault-tolerance and performance. A nice educational overview of the various levels of 
			RAID is offered by Advanced Computer &amp; Network Corporation at 
			<docbook:link xlink:href='http://www.acnc.com/04_00.html'></docbook:link>. But what about mainframe 
			disk arrays?
		</docbook:para>
		<docbook:para>
			The RAMAC Virtual Array (RVA) came first for the mainframe and it was based on virtual disks that emulated 3380s and 
			3390s. The RVA dynamically maps functional volumes to physical drives. This mapping structure is contained in a series 
			of tables stored in the RVA control unit. RVA was OEM'ed from Storage Technology Corp. (STK) which is now part of Oracle. 
		</docbook:para>
		<docbook:para>
			The ESS (Enterprise Storage System), also known as Shark, followed when the STK OEM agreement expired. The ESS is scalable 
			from 420GB to 55.9 TB. It offers improved performance over RAMAC, especially for prefetch and analytical queries. 
		</docbook:para>
		<docbook:para>
			And the latest and greatest IBM mainframe disk technology is the DS8000, which employs virtualized disk. It adds 
			functionality for storage pool striping, thin provisioning, and quick initialization, among other innovations. Its 
			capacity scales linearly from 1.1 TB up to 192 TB (up to 320 TB with turbo models).
		</docbook:para>
		<docbook:para>
			Of course, IBM is not the only game in town for mainframe storage. EMC, Hewlett Packard, Hitachi, and Sun also offer 
			modern disk arrays for the mainframe. 
		</docbook:para>
	</docbook:section>
	<docbook:section>
		<docbook:title>
			Cache Versus Buffer
		</docbook:title>
		<docbook:para>
			Modern disk arrays cache data, but so does DB2. In the old days we used to disable disk cache for DB2, but no longer. 
			There are two DSNZPARMs you should be aware of that can be setup to properly control disk caching for DB2 data sets.
		</docbook:para>
		<docbook:para>
			First up is the SEQCACH parameter. The original meaning of this parameter, for 3390 DASD, was whether DB2 I/O should 
			bypass the disk cache, but the meaning is different now because you do not want to bypass the cache on modern storage 
			arrays. There are two options:
			<docbook:variablelist>
				<docbook:varlistentry>
					<docbook:term>BYPASS</docbook:term>
					<docbook:listitem>
						The disk will perform Sequential Detection
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>SEQ</docbook:term>
					<docbook:listitem>
						Creates an explicit Prefetch request; the recommendation is to use this setting for improved performance.
					</docbook:listitem>
				</docbook:varlistentry>
			</docbook:variablelist>
		</docbook:para>
		<docbook:para>
			The second DSNZPARM is SEQPRES, which is similar to SEQCACH, but for DB2 LOAD and REORG utilities. If set to YES the 
			Cache is more likely to retain pages for subsequent update, particularly when processing NPIs. The general recommendation 
			is to set to SEQCACH to YES.
		</docbook:para>
		<docbook:para>
			Keep in mind, too, that your storage administrators should be aware that DB2 buffering may cause DB2 data to use the disk 
			cache differently than other non-database data sets. But that doesn’t mean that DB2 is not benefiting from disk caching.
		</docbook:para>
	</docbook:section>

	<docbook:section>
		<docbook:title>
			A Little Bit About DFSMS
		</docbook:title>
		<docbook:para>
			DFSMS is IBM’s Data Facility Storage Management System. It offers data management, backup and HSM software from IBM 
			mainframes, combining backup, copy, HSM and device driver routines into a single package. So DFSMS is actually multiple 
			products; it is a suite of data and storage management offerings:-
			<docbook:variablelist>
				<docbook:varlistentry>
					<docbook:term>DFSMSdfp</docbook:term>
					<docbook:listitem>
						Data Facility Product - provides the logical and physical input and output for z/OS storage, it keeps track of 
						all data and programs managed within z/OS, and it provides data access both for native z/OS applications and 
						other platforms. 
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>DFSMSdss</docbook:term>
					<docbook:listitem>
						This is a priced optional feature. It is a DASD data and space management tool for moving and copying data. 
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>DFSMShsm</docbook:term>
					<docbook:listitem>
						Hierarchical Storage Manager - a priced optional feature for managing low-activity and inactive data. It 
						provides backup, recovery, migration, and space management functions. 
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>DFSMSrmm</docbook:term>
					<docbook:listitem>
						Removable Media Manager  - a priced optional feature for managing removable media resources (e.g. IBM's 
						Virtual Tape Server).
					</docbook:listitem>
				</docbook:varlistentry>
				<docbook:varlistentry>
					<docbook:term>DFSMStvs</docbook:term>
					<docbook:listitem>
						Transactional VSAM Services – is another priced optional feature that enables batch jobs and CICS online 
						transactions to update shared VSAM data sets concurrently. 
					</docbook:listitem>
				</docbook:varlistentry>
			</docbook:variablelist>
		</docbook:para>
		<docbook:para>
			But we are not going to delve into all of these various components. What we are most interested in is how DB2 can benefit 
			from DFSMS. Using DFSMS, a DB2 DBA can simplify the interaction of DB2 database creation and storage specification. It can 
			deliver:-
			<docbook:itemizedlist>
				<docbook:listitem>Simplified data allocation</docbook:listitem>
				<docbook:listitem>Improved allocation control</docbook:listitem>
				<docbook:listitem>Improved performance management</docbook:listitem>
				<docbook:listitem>Automated disk space management</docbook:listitem>
				<docbook:listitem>Improved data availability management</docbook:listitem>
				<docbook:listitem>Simplified data movement</docbook:listitem>
			</docbook:itemizedlist>
		</docbook:para>
		<docbook:para>
			DFSMS has the necessary flexibility to support everything DB2 DBAs may want to accomplish in terms of data set placement 
			and design. In this day and age there is no reason to not take advantage of DFSMS for DB2 data sets. However, to achieve 
			a successful implementation, an agreement between the storage administrator and the DB2 administrator is required so that 
			they can together establish an environment that satisfies both their objectives.
		</docbook:para>
		<docbook:para>
			SMS Data Classes, Storage Classes, Management Classes, and Storage Groups can be used along with SMS ACS (Automatic Class 
			Selection) routines to set up and automate DB2 data set allocation and placement. SMS Storage Groups contains volumes that 
			satisfy the service requirements of the data sets allocated to them. They can handle more than one type of data. Separate 
			Storage Groups should be defined for production table spaces, active logs, other production data, and non-production data. 
			ACS routines assign data sets to SMS storage classes. For example, indexes can be assigned to to one SMS storage class and 
			table spaces to a different SMS storage class. For DB2 Storage Groups using SMS the volume list is set to ‘*’.
		</docbook:para>
		<docbook:para>
			As of DB2 9, DATACLAS, MGMTCLAS, and STORCLAS can be specified in DB2 Storage Groups, and if so, then the VOLUMES clause 
			can be omitted. If the VOLUMES clause is omitted, the volume selection is controlled by SMS. Keep in mind, though, that 
			when processing the VOLUMES, DATACLAS, MGMTCLAS, or STORCLAS clauses, DB2 does not check the existence of the volumes or 
			classes or determine the types of devices that are identified or if SMS is active. Later, when the storage group allocates 
			data sets, the list of volumes is passed in the specified order to Data Facilities (DFSMSdfp). 
		</docbook:para>
		<docbook:para>
			Basically, using SMS with DB2 is the sane thing to do these days because the new disk architectures, with concepts like 
			log structured files and with cache in the gigabyte sizes, render conventional database design rules based on data set 
			placement less important. In most cases, placement is not an issue, and when it is, SMS classes and ACS routines can be 
			setup to take care of things.
		</docbook:para>
	</docbook:section>

	<docbook:section>
		<docbook:title>What About Extents?</docbook:title>
		<docbook:para>
			Some folks think “With RAID/modern storage devices and new DB2 and z/OS features, extents are no longer anything to worry 
			about.” But this is not exactly true. For one thing, the latest extent management features only work with SMS-managed 
			data sets, so if you are still using user-managed data sets then all of the old rules apply! 
		</docbook:para>
		<docbook:para>
			For SMS-managed data set you can have up to 123 extents on each of 59 volumes. So as of z/OS 1.7, the limit is 7,257 
			extents for a data set instead of the 255 we’ve been used to for some time. Again though, to enable this requires DFSMS 
			(modify the DFSMS Data Class to set the Extent Constraint Removal to YES).
		</docbook:para>
		<docbook:para>
			Extent consolidation also requires SMS-managed STOGROUPs. If a new extent is adjacent to old, they will be merged together 
			automatically. This can result in some extents being larger than the PRIQTY or SECQTY specification(s). Note that this 
			feature was introduced in z/OS 1.5.
		</docbook:para>
		<docbook:para>
			OK, so what if everything is SMS-controlled? Then extents don’t matter, right? Well, not really. Even then it is possible 
			for extents to impact performance. Each extent on a disk file has different control blocks controlling access. This means 
			that elapsed time can increase if there is heavy insert activity. For other types of processing (read and update) the 
			number of extents really does not impact on performance. 
		</docbook:para>
		<docbook:para>
			At any rate, things are not like the olden days where you had to regularly monitor extents and clean them up all the time 
			by reorganizing your table spaces and index spaces. Oh, we want to clean those extents up periodically, but storage 
			administrators have other methods of reducing extents that perhaps can be quicker and/or easier, for example.
			<docbook:itemizedlist>
				<docbook:listitem>DFSMShsm MIGRATE and RECALL functions	</docbook:listitem>
				<docbook:listitem>DFSMSdss COPY or DUMP and RESTORE functions</docbook:listitem>
				<docbook:listitem>DEFRAG with the CONSOLIDATE keyword</docbook:listitem>
				<docbook:listitem>Other products: e.g. Real Time Defrag</docbook:listitem>
			</docbook:itemizedlist>
		</docbook:para>
		<docbook:para>
			As of V8, DB2 can allocate sliding scale secondary extents. This is enabled by setting MGEXTSZ DSNZPARM to YES. Note that 
			the default is NO for V8, but changed to YES automatically when you upgrade to DB2 9. With sliding scale extents the extent 
			sizes allocated gradually increase. DB2 uses a sliding scale for secondary extent allocations of table spaces and indexes 
			when:
			<docbook:itemizedlist>
				<docbook:listitem>
					You do not specify a value for the SECQTY option of a CREATE TABLESPACE or CREATE INDEX statement
				</docbook:listitem>
				<docbook:listitem>
					You specify a value of -1 for the SECQTY option of an ALTER TABLESPACE or ALTER INDEX statement.
				</docbook:listitem>
			</docbook:itemizedlist> 
		</docbook:para>
		<docbook:para>
			Otherwise, DB2 uses the SECQTY value for secondary extent allocations, if one is explicitly specified (and the SECQTY value 
			is larger than the value that is derived from the sliding scale algorithm). If the table space or index space has a SECQTY 
			greater than 0, the primary space allocation of each subsequent data set is the larger of the SECQTY setting and the value 
			that is derived from a sliding scale algorithm. 
		</docbook:para>
		<docbook:para>
			Without going into all of the gory details, sliding scale extent allocation can help to reduce the number of extents for 
			your Db2 objects as they grow in size over time. And it can help when you do not have a firm understanding of how your 
			data will grow over time.
		</docbook:para>
	</docbook:section>

	<docbook:section>
		<docbook:title>Another Thing to Think About</docbook:title>
		<docbook:para>
			Every now and then I hear from a DB2 DBA complaining about index growth. They’ll say something like this: “My index 
			keeps growing and growing and taking additional extents, even after deleting data from the base table. What is going on?” 
		</docbook:para>
		<docbook:para>
			Well, deleted index keys are not physically deleted, but marked as pseudo-deleted. This can cause an index to grow even as 
			the table data remains at relatively the same level. And it can result in a high CPU cost for index scans because DB2 scans 
			all of the entries, even the pseudo-deleted ones. For this reason, you should keep an eye on tables with a lot of delete 
			activity and periodically reorganize their indexes. You can track pseudo-deleted index keys in SYSINDEXPART if using 
			RUNSTATS or SYSINDEXSPACESTATS if using real time statistics. Consider reorganizing these indexes when pct of pseudo-deleted 
			entries is:
			<docbook:itemizedlist>
				<docbook:listitem>Greater than 10% for non Data Sharing</docbook:listitem>
				<docbook:listitem>Greater than 5% for Data Sharing</docbook:listitem>
			</docbook:itemizedlist> 
		</docbook:para>
	</docbook:section>

	<docbook:section>
		<docbook:title>Best Practices</docbook:title>
		<docbook:para>
			In general, you should adopt best practices for managing your DB2-related storage. Keep up-to-date on DB2/storage 
			functionality and adopt new practices in the latest releases of DB2.
		</docbook:para>		
		<docbook:para>
			It is a good idea to perform regular and proactive monitoring. Examples of things you should be tracking include:
			<docbook:orderedlist>
				<docbook:listitem>
					Space display and monitoring for your entire DB2 system.
				</docbook:listitem>
				<docbook:listitem>
					Space display and monitoring of individual DB2 databases.
				</docbook:listitem>
				<docbook:listitem>
					Space display and monitoring of all of your table spaces and indexes.
				</docbook:listitem>
				<docbook:listitem>
					Display and monitoring of the Storage Groups and the associated volumes of a DB2 system. (Data, Workfile, 
					Image Copies, Logs, Archives, Sort/Work etc.)
				</docbook:listitem>
				<docbook:listitem>
					The ability to display all VSAM data sets for all table spaces and indexes (Used, Allocated, Primary and 
					Secondary Quantity, Volumes) and monitoring of the extents for each.
				</docbook:listitem>
				<docbook:listitem>
					Display of the Page Sets of table spaces and indexes that reach their maximum size and maximum number of data sets.
				</docbook:listitem>
				<docbook:listitem>
					Tracking of image copy backup data sets, including the intelligent HSM migration of same. You should be able to 
					reduce backups by track which are not used for local recovery (to CURRENT), as well as data sets older than the 
					last full image copy (including dual and remote backups).
				</docbook:listitem>
				<docbook:listitem>
					Managing the deletion of Image copy backup datasets that are no longer needed because of DROP, DROP/CREATE or 
					MODIFY TABLESPACE (‘orphaned‘, not listed in SYSIBM.SYSCOPY).
				</docbook:listitem>
			</docbook:orderedlist>
		</docbook:para>
		<docbook:para>
			If possible, build alerts to inform you of problems, shortages, and potential errors. When possible, automate remediation 
			tactics so that the alert tells you what happened, as well as what was done to correct the issue. Tools may be able to 
			assist in automating reaction to shortages, potential errors, superfluous data sets, etc. For example, refer to Figures 
			4 and 5.
		</docbook:para>

Figure 4. Automated Storage Alerts


Figure 5. Tracking the Growth of DB2 Storage Space 

	</docbook:section>
	
	<docbook:section>
		<docbook:title>Summary</docbook:title>
			<docbook:para>
				Finally, there is a people issue that needs to be addressed. The DBA and the storage administrator will need to 
				cooperate in order to facilitate proper database storage. Remember, other types of data that are not stored in 
				the DBMS will need to be saved on disk, too. Databases use storage differently than non-database data. Indexing, 
				partitioning, clustering, and separation of data will cause the database to require more storage, across more drives, 
				and using cache differently than most storage administrators may anticipate. 
			</docbook:para>
			<docbook:para>
				DBAs need to work storage administrators to make sure that each understands the other domain. And to make sure that 
				s/he has the storage information needed to properly administer DB2. The better the DBA communicates, and the better 
				the relationship is between these two IT professionals, the better your database applications will perform. And that 
				is what it is all really about, right?
			</docbook:para>
	</docbook:section>
</docbook:article>

	<!-- Column 3 -->

	<docbook:article>
	</docbook:article>

</docbook:book>